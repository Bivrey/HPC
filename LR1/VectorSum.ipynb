{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49494bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\belia\\anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py:726: NumbaPerformanceWarning: \u001b[1mGrid size (2) < 2 * SM count (76) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "C:\\Users\\belia\\anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py:726: NumbaPerformanceWarning: \u001b[1mGrid size (2) < 2 * SM count (76) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "C:\\Users\\belia\\anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py:726: NumbaPerformanceWarning: \u001b[1mGrid size (20) < 2 * SM count (76) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Size | CPU Time (s) | GPU Time (s) |  Speedup\n",
      "--------------------------------------------------\n",
      "      1000 |     0.000013 |     0.015074 |     0.00\n",
      "     10000 |     0.000007 |     0.000546 |     0.01\n",
      "    100000 |     0.000040 |     0.000380 |     0.10\n",
      "   1000000 |     0.000544 |     0.000390 |     1.39\n",
      "  10000000 |     0.009921 |     0.002213 |     4.48\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from numba import cuda, float32\n",
    "\n",
    "# CPU функция для подчсета суммы\n",
    "def sum_cpu(vector, repeat=10):\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in range(repeat):\n",
    "        result = np.sum(vector)\n",
    "    elapsed_time = (time.perf_counter() - start_time) / repeat\n",
    "    return result, elapsed_time\n",
    "\n",
    "# GPU функция для подсчета суммы\n",
    "@cuda.jit\n",
    "def sum_gpu_kernel(vector, partial_sums):\n",
    "    shared_mem = cuda.shared.array(512, dtype=float32)\n",
    "    tid = cuda.threadIdx.x\n",
    "    i = cuda.blockIdx.x * cuda.blockDim.x + tid\n",
    "\n",
    "    # Загружаем данные в shared memory\n",
    "    if i < vector.size:\n",
    "        shared_mem[tid] = vector[i]\n",
    "    else:\n",
    "        shared_mem[tid] = 0\n",
    "    cuda.syncthreads()\n",
    "\n",
    "    # Редукция\n",
    "    step = 1\n",
    "    while step < cuda.blockDim.x:\n",
    "        if tid % (2 * step) == 0:\n",
    "            shared_mem[tid] += shared_mem[tid + step]\n",
    "        cuda.syncthreads()\n",
    "        step *= 2\n",
    "\n",
    "    # Сохраняем результат\n",
    "    if tid == 0:\n",
    "        partial_sums[cuda.blockIdx.x] = shared_mem[0]\n",
    "\n",
    "def sum_gpu(vector, repeat=10):\n",
    "    threads_per_block = 512\n",
    "    blocks_per_grid = (vector.size + threads_per_block - 1) // threads_per_block\n",
    "\n",
    "    vector_device = cuda.to_device(vector)\n",
    "    partial_sums_device = cuda.device_array(blocks_per_grid, dtype=np.float32)\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    for _ in range(repeat):\n",
    "        sum_gpu_kernel[blocks_per_grid, threads_per_block](vector_device, partial_sums_device)\n",
    "        cuda.synchronize()\n",
    "    elapsed_time = (time.perf_counter() - start_time) / repeat\n",
    "\n",
    "    partial_sums = partial_sums_device.copy_to_host()\n",
    "    total_sum = np.sum(partial_sums)\n",
    "    return total_sum, elapsed_time\n",
    "\n",
    "def main():\n",
    "    vector_sizes = [1_000, 10_000, 100_000, 1_000_000, 10_000_000]\n",
    "    results = []\n",
    "\n",
    "    for size in vector_sizes:\n",
    "        vector = np.random.rand(size).astype(np.float32)\n",
    "\n",
    "        # CPU вычисление\n",
    "        cpu_sum, cpu_time = sum_cpu(vector)\n",
    "\n",
    "        # GPU вычисление\n",
    "        gpu_sum, gpu_time = sum_gpu(vector)\n",
    "\n",
    "        # Проверка корректности\n",
    "        assert np.isclose(cpu_sum, gpu_sum, atol=1e-5), \"Суммы не совпадают!\"\n",
    "\n",
    "        # Запись результатов\n",
    "        if gpu_time == 0:\n",
    "            speedup = float('inf')\n",
    "        else:\n",
    "            speedup = cpu_time / gpu_time\n",
    "        \n",
    "        results.append((size, cpu_time, gpu_time, speedup))\n",
    "\n",
    "    print(f\"{'Size':>10} | {'CPU Time (s)':>12} | {'GPU Time (s)':>12} | {'Speedup':>8}\")\n",
    "    print(\"-\" * 50)\n",
    "    for size, cpu_time, gpu_time, speedup in results:\n",
    "        print(f\"{size:>10} | {cpu_time:>12.6f} | {gpu_time:>12.6f} | {speedup:>8.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79578be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
